# ------------------------------------------------------------
# This configuration uses pretrained weights, anchors, and class
# labels from the official ONNX Model Zoo:
# https://github.com/onnx/models/blob/main/validated/vision/object_detection_segmentation/yolov4
#
# Ensure that the following files are downloaded from the repo above:
# - yolov4.onnx
# - yolov4_anchors.txt
# - coco.names
# and placed in ./models/yolov4/
#
# Alternatively, specify custom paths to your own versions of
# weights, anchors, and class label files.
# ------------------------------------------------------------

- mode : image
  images_path: ./data/mini_data
  groundtruth_path: ./layout/mini_data.csv
  model_name: YOLOv4
  adapter_name: AdapterYOLOv4
  path_classes: ./models/yolov4/coco.names
  path_anchors: ./models/yolov4/yolov4_anchors.txt
  path_weights: ./models/yolov4/yolov4.onnx
  batch_size: 2
  confidence: 0.1
  nms_threshold: 0.213
  scale: 1.0      # placeholder
  size: 416 416
  mean:           # placeholder
  swapRB:         # placeholder